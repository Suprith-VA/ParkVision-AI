{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Intelligent_Parking.ipynb","provenance":[],"authorship_tag":"ABX9TyM2aMahOcVkHgpJA4IqvroL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Kwb4gemdoQXE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594138936402,"user_tz":-330,"elapsed":931,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}},"outputId":"37566aee-f31b-4a70-90fc-0258969eaadb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9yxIyPMHpIAt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594135941778,"user_tz":-330,"elapsed":3701,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}},"outputId":"75ee06db-8100-45e9-bc5c-82190647a2c8"},"source":["!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WegmbK1ppStS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594139448180,"user_tz":-330,"elapsed":1337,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}}},"source":["import os\n","os.chdir(\"/content/drive/My Drive/Colab Notebooks/Intelligent_parking using Mask RCNN\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vbd2w1nAqoLq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1594135565146,"user_tz":-330,"elapsed":3196,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}},"outputId":"7a7a50fb-ba00-4825-e92b-37fb43f6731f"},"source":["!ls"],"execution_count":4,"outputs":[{"output_type":"stream","text":["1.15.0\timages\t\t\tMANIFEST.in\t    output_frames     setup.cfg\n","assets\tIntelligent_Parking.py\tmask_rcnn_coco.h5   README.md\t      setup.py\n","build\tInt_Park.ipynb\t\tmask_rcnn.egg-info  requirements.txt  Videos\n","dist\tLICENSE\t\t\tmrcnn\t\t    samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ipPhF3VXq0Qn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":870},"executionInfo":{"status":"ok","timestamp":1594133707666,"user_tz":-330,"elapsed":58433,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}},"outputId":"8402b436-f852-40ca-9d27-b572da10273b"},"source":["!pip3 install --upgrade tensorflow==1.3\n","!pip3 install --upgrade keras==2.0.8"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Collecting tensorflow==1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9f/57e1404fc9345759e4a732c4ab48ab4dd78fd1e60ee1270442b8850fa75f/tensorflow-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (43.5MB)\n","\u001b[K     |████████████████████████████████| 43.6MB 64kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (1.18.5)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (3.10.0)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (0.34.2)\n","Collecting tensorflow-tensorboard<0.2.0,>=0.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/31/bb4111c3141d22bd7b2b553a26aa0c1863c86cb723919e5bd7847b3de4fc/tensorflow_tensorboard-0.1.8-py3-none-any.whl (1.6MB)\n","\u001b[K     |████████████████████████████████| 1.6MB 41.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.3) (1.12.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.3) (47.3.1)\n","Collecting html5lib==0.9999999\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n","\u001b[K     |████████████████████████████████| 890kB 42.0MB/s \n","\u001b[?25hCollecting bleach==1.5.0\n","  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (3.2.2)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (1.0.1)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (1.6.1)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow==1.3) (3.1.0)\n","Building wheels for collected packages: html5lib\n","  Building wheel for html5lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for html5lib: filename=html5lib-0.9999999-cp36-none-any.whl size=107220 sha256=d56603485253a0fbededd8d64f3356a8d8a8444014e5105f476da9c0724458a0\n","  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n","Successfully built html5lib\n","Installing collected packages: html5lib, bleach, tensorflow-tensorboard, tensorflow\n","  Found existing installation: html5lib 1.0.1\n","    Uninstalling html5lib-1.0.1:\n","      Successfully uninstalled html5lib-1.0.1\n","  Found existing installation: bleach 3.1.5\n","    Uninstalling bleach-3.1.5:\n","      Successfully uninstalled bleach-3.1.5\n","  Found existing installation: tensorflow 2.2.0\n","    Uninstalling tensorflow-2.2.0:\n","      Successfully uninstalled tensorflow-2.2.0\n","Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorflow-1.3.0 tensorflow-tensorboard-0.1.8\n","Collecting keras==2.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/3f/d117d6e48b19fb9589369f4bdbe883aa88943f8bb4a850559ea5c546fefb/Keras-2.0.8-py2.py3-none-any.whl (276kB)\n","\u001b[K     |████████████████████████████████| 276kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.18.5)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.12.0)\n","Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.4.1)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (3.13)\n","\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.0.8 which is incompatible.\u001b[0m\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.3.1\n","    Uninstalling Keras-2.3.1:\n","      Successfully uninstalled Keras-2.3.1\n","Successfully installed keras-2.0.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2JBdjmXAt4fP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1594139459458,"user_tz":-330,"elapsed":1716,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}},"outputId":"dcdadc90-0cac-4862-d763-4b32d0972ca0"},"source":["import os\n","import numpy as np\n","import cv2 as openCV\n","import matplotlib as plt\n","import mrcnn.config\n","import mrcnn.utils"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Ny2BamK2uliJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594139491290,"user_tz":-330,"elapsed":16717,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}},"outputId":"bc1ac951-63ea-4883-b4fb-c6bb7093e1ec"},"source":["from mrcnn.model import MaskRCNN\n","from pathlib import Path"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qauDWKp7u-_3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1594138984829,"user_tz":-330,"elapsed":3306,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}},"outputId":"be37d9e4-a933-41ce-d578-433825be5f95"},"source":["!nvidia-smi"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Tue Jul  7 16:23:04 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YZO1Y2WCwN5-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594139491293,"user_tz":-330,"elapsed":1179,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}}},"source":["# set up config of Mask-RCNN \n","class Config_Mask_RCNN(mrcnn.config.Config):\n","    NAME = \"coco_pretrained_model_config\"\n","    DETECTION_MIN_CONFIDENCE = 0.6\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","    NUM_CLASSES = 1 + 80"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"2f2jcFzkx8tX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594139497897,"user_tz":-330,"elapsed":964,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}}},"source":["# 1st level directory    \n","DIR_LIB = Path(\".\")\n","# Directoy of the RCNN model \n","DIR_MODEL = os.path.join(DIR_LIB, \"logs\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"kuEj6Z7RyEbD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594139500520,"user_tz":-330,"elapsed":1219,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}}},"source":["# Mask RCNN model path\n","coco_model = os.path.join(DIR_LIB, \"mask_rcnn_coco.h5\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"dDD3K-qVyPMV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594139508044,"user_tz":-330,"elapsed":7064,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}}},"source":["rcnn_model = MaskRCNN(mode = \"inference\", model_dir = DIR_MODEL, config = Config_Mask_RCNN())\n","rcnn_model.load_weights(coco_model, by_name=True)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zsnqk7zbydr0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594139509363,"user_tz":-330,"elapsed":1295,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}}},"source":["# input video for test\n","VIDEO_INPUT = \"Videos/Video.mp4\"\n","VIDEO_OUTPUT = './Final_Video.avi'\n","video_frames = openCV.VideoCapture(VIDEO_INPUT)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"bmPf-iEiy8GB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594139510970,"user_tz":-330,"elapsed":1325,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}}},"source":["# getting the bounding boxes from the frame\n","def get_boxes_on_vehicles(bound_boxes, class_ids):\n","    vehicle_boxes = []\n","\n","    # iterate through all the boxes to the vehicles\n","    for i, box in enumerate(bound_boxes):\n","        if class_ids[i] in [3, 4, 8, 6]:\n","            vehicle_boxes.append(box)\n","\n","    return np.array(vehicle_boxes)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ympY_cbUzBF0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594139512265,"user_tz":-330,"elapsed":668,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}}},"source":["# parking slots spotted\n","parked_vehicle_boxes = None\n","# Loop over all frames\n","frame_count = 0\n"," # Assume no spaces are free until we find one that is free\n","free_space = False\n","video_writer = None"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"l179bPdqzI8S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594139967770,"user_tz":-330,"elapsed":55652,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}},"outputId":"7dfe7c80-2d8e-47c5-af1f-aa9615babc48"},"source":["while video_frames.isOpened():\n","    success, frame = video_frames.read()\n","\n","    if not success:\n","        print(\"Last frame processed or video format is corrupted\")\n","        break\n","\n","    elif frame_count < 60:\n","      # compare two frames to cancel the detection of moving vehicle\n","      success, next_frame = video_frames.read()\n","      diff_frames = openCV.absdiff(frame, next_frame)  \n","      grey_motion = openCV.cvtColor(diff_frames, openCV.COLOR_BGR2GRAY)\n","      blur_pixel = openCV.GaussianBlur(grey_motion, (1, 1), 0)\n","      ret, threshold = openCV.threshold(blur_pixel, 20, 255, openCV.THRESH_BINARY)\n","      \n","      # erode the car which is moving so that it is not detected by MASKRCNN.\n","      dilated = openCV.dilate(threshold, np.ones((10, 10), np.uint8), iterations = 1 )\n","      eroded = openCV.erode(dilated, np.ones((10, 10), np.uint8), iterations = 1 )\n","\n","      # processed frame by adding contours so that MaskRCNN doesn't get applied\n","      c, h = openCV.findContours(eroded, openCV.RETR_TREE, openCV.CHAIN_APPROX_SIMPLE)\n","      next_frame = openCV.drawContours(next_frame, c, -1, (0,0,0), openCV.FILLED)\n","\n","      if frame_count%5 == 0:\n","        print(\"Current frame number : \" + str(frame_count))\n","        plt.pyplot.imshow(next_frame)\n","        plt.pyplot.show()\n","        \n","      frame_count = frame_count + 1\n","      continue \n","\n","    # Converting the BGR color to RGB color.     \n","    rgb_image = frame[:, :, ::-1] \n","\n","    # Detect cars using Mask RCNN\n","    if parked_vehicle_boxes is None:\n","        print(\"Marking vehicles. Frame number:  \", frame_count)\n","        results = rcnn_model.detect([rgb_image], verbose=0)\n","        res = results[0]\n","        parked_vehicle_boxes = get_boxes_on_vehicles(res['rois'], res['class_ids'])\n","\n","    elif frame_count%200 == 0 and len(parked_vehicle_boxes) != 0:\n","        results = rcnn_model.detect([rgb_image], verbose=0)\n","        res = results[0]\n","\n","        # Get where vehicles are currently located in the frame\n","        vehicle_boxes = get_boxes_on_vehicles(res['rois'], res['class_ids'])\n","\n","        # how much those vehicles overlap with the known parking slots\n","        overlaps = mrcnn.utils.compute_overlaps(parked_vehicle_boxes, vehicle_boxes)\n","\n","        # For all the parking slots found around parked vehicles\n","        for parking_slot, overlap_areas in zip(parked_vehicle_boxes, overlaps):\n","\n","            # find the max amount it was covered by any\n","            # vehicle detected for this slot\n","            max_IoU_overlap = np.max(overlap_areas)\n","\n","            # corner co-ordinates of the parking slot\n","            y1, x1, y2, x2 = parking_slot\n","\n","            # vehicle has left the slot\n","            if max_IoU_overlap < 0.15:\n","                # Parking slot is empty\n","                openCV.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n","                formatedText = \"Parking Slot free : \"\n","                openCV.putText(frame, formatedText, (x1 + 6, y2 - 6), openCV.FONT_HERSHEY_SIMPLEX, 0.2, (255, 255, 255))\n","                free_space = True\n","            else:\n","                # Parking slot is still occupied \n","                openCV.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n","\n","            # Write the IoU measurement inside the box\n","            # font = openCV.FONT_HERSHEY_DUPLEX\n","            # openCV.putText(frame, f\"{max_IoU_overlap:0.2}\", (x1 + 6, y2 - 6), font, 0.7, (255, 255, 255))\n","\n","    img = str(frame_count) + \".jpg\"\n","    img = os.path.join('./output_frames', img)\n","    openCV.imwrite(img, frame)\n","    frame_count+=1\n","\n","    #if video_writer is None:\n","\t\t# Saving the Video\n","\t  #  fourcc = openCV.VideoWriter_fourcc(*\"MJPG\")\n","\t  #  video_writer = openCV.VideoWriter(VIDEO_OUTPUT, fourcc, 15, (frame.shape[1], frame.shape[0]), True)\n","    #video_writer.write(frame)\n","\n","print(\"Video completed\")\n","# video_writer.release()\n","video_frames.release()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Last frame processed or video format is corrupted\n","Video completed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hXjfBvMD6zBg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594136214055,"user_tz":-330,"elapsed":5073,"user":{"displayName":"Suprith Vasishta","photoUrl":"","userId":"10943263893450723085"}},"outputId":"199cd5c6-9df0-43dc-a5b4-8935cc7aa70f"},"source":["#create video including all the frames in the ak folder\n","import glob\n","\n","images = list(glob.iglob(os.path.join('./output_frames', '*.*')))\n","images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n","\n","# Get all image file paths to a list.\n","# Sort the images by name index.\n","# images = sorted(images, key=lambda x: float(os.path.split(x)[1][:-3]))\n","\n","def make_video(outvid, images=None, fps=30, size=None,\n","               is_color=True, format=\"FMP4\"):\n","    \"\"\"\n","    Create a video from a list of images.\n"," \n","    @param      outvid      output video\n","    @param      images      list of images to use in the video\n","    @param      fps         frame per second\n","    @param      size        size of each frame\n","    @param      is_color    color\n","    @param      format      see http://www.fourcc.org/codecs.php\n","    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n","    \"\"\"\n","    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n","    fourcc = VideoWriter_fourcc(*format)\n","    vid = None\n","    for image in images:\n","        if not os.path.exists(image):\n","            raise FileNotFoundError(image)\n","        img = imread(image)\n","        if vid is None:\n","            if size is None:\n","                size = img.shape[1], img.shape[0]\n","            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n","        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n","            img = resize(img, size)\n","        vid.write(img)\n","    vid.release()\n","    return vid\n","  \n","make_video('./FinalVideo.mp4', images, fps=30)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<VideoWriter 0x7f1a47f2db90>"]},"metadata":{"tags":[]},"execution_count":14}]}]}